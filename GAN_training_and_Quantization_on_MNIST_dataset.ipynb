{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training GAN on MNIST dataset.\n",
        "\n",
        "Following activities are carried out to perform the reduction in size of the GAN model.\n",
        "\n",
        "\n",
        "1. We will be using 'tflit' for using our model in mobile devices for faster inference.\n",
        "\n",
        "2. Model is later quantized and retrained with quantization aware training. (Model Pruning)\n",
        "\n",
        "3. Images obtained can be observed in 'quantized_images' folder\n",
        "\n",
        "4. For better quality of results train the images for 100k epochs.\n",
        "\n",
        "5. There can be problem of mode collapse with quantization awared training. This can be taken care with modeling the latent vector like in StyleGAN. "
      ],
      "metadata": {
        "id": "IXfa90gFWSo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVqjtCdH_PjZ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define input image dimensions\n",
        "#Large images take too much time and resources.\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)"
      ],
      "metadata": {
        "id": "8PxuPoxgWjGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,) #1D array of size 100 (latent vector / noise)\n",
        "\n",
        "    model = keras.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=noise_shape),\n",
        "      keras.layers.Dense(784),\n",
        "      keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(np.prod(img_shape), activation='tanh'),\n",
        "      keras.layers.Reshape(img_shape)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8u4wAcV3WoP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        \n",
        "    keras.layers.Flatten(input_shape=img_shape),\n",
        "    keras.layers.Dense(512),\n",
        "    keras.layers.LeakyReLU(alpha=0.2),\n",
        "    keras.layers.Dense(256),\n",
        "    keras.layers.LeakyReLU(alpha=0.2),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "        \n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Convert to float and Rescale -1 to 1 (Can also do 0 to 1)\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "#Add channels dimension. As the input to our gen and discr. has a shape 28x28x1.\n",
        "    X_train = np.expand_dims(X_train, axis=3) \n",
        "\n",
        "    half_batch = int(batch_size / 2) \n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "        # Generate a half batch of fake images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images, separately\n",
        "        #Research showed that separate training is more effective. \n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    #take average loss from real and fake images. \n",
        "    #\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)\n"
      ],
      "metadata": {
        "id": "ghiJ3Uq0Wu-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/sample_data/images/mnist_%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "5VkPCaZUXB-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = 'adam'\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "generator = build_generator()\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "generator.summary() \n",
        "z = keras.layers.Input(shape=(100,))   #Our random input to the generator\n",
        "img = generator(z)   \n",
        "discriminator.trainable = False   \n",
        "valid = discriminator(img)  #Validity check on the generated image\n",
        "\n",
        "combined = keras.models.Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "train(epochs=10000, batch_size=128, save_interval=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "L9ESjYgUXO4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('./generator/')  #Test the model on GAN4_predict..."
      ],
      "metadata": {
        "id": "sukW6s3wjuVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.save('./discriminator/')  #Test the model on GAN4_predict..."
      ],
      "metadata": {
        "id": "N72mLcqZdvFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./generator\")\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "ZASZbQQNi95P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./generator\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "metadata": {
        "id": "RVeqWsJ_jNfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_model)"
      ],
      "metadata": {
        "id": "Cweo8Z4IkrZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_quant_model)"
      ],
      "metadata": {
        "id": "VZq8c757kuL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "8TFQhD2WD5tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = tfmot.quantization.keras.quantize_model(generator)\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "id": "Zpj5xaJMlSK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "z = keras.layers.Input(shape=(100,))   #Our random input to the generator\n",
        "img = q_aware_model(z)\n",
        "valid = discriminator(img) \n",
        "combined = keras.models.Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "train(epochs=10000, batch_size=128, save_interval=1000)"
      ],
      "metadata": {
        "id": "WhvjLLxUEQEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_qaware_model = converter.convert()\n",
        "\n"
      ],
      "metadata": {
        "id": "7dIPJ2gbFK4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_qaware_model)"
      ],
      "metadata": {
        "id": "FKoWfLOnFRFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}